{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"TFiPS_C2W2ex2_CatVsDogKaggleBigDataset_ImageGeneratorAugmentation_ConvNN.ipynb","provenance":[{"file_id":"https://github.com/lmoroney/dlaicourse/blob/master/Exercises/Exercise%205%20-%20Real%20World%20Scenarios/Exercise%205%20-%20Question.ipynb","timestamp":1584312110376},{"file_id":"1dGHF5_gCd_iW3blaWG-kNce153CHvM-I","timestamp":1550529081161}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"_D5V5lUYBsD-","colab_type":"text"},"source":["Coursera Colab link: https://colab.research.google.com/github/lmoroney/dlaicourse/blob/master/Exercises/Exercise%206%20-%20Cats%20v%20Dogs%20with%20Augmentation/Exercise%206%20-%20Question.ipynb\n","\n","Solution Coursera Colab link: https://colab.research.google.com/github/lmoroney/dlaicourse/blob/master/Exercises/Exercise%206%20-%20Cats%20v%20Dogs%20with%20Augmentation/Exercise%206%20-%20Answer.ipynb"]},{"cell_type":"code","metadata":{"id":"dn-6c02VmqiN","colab_type":"code","outputId":"c401598a-ab4d-4df9-dad7-e58adcfeeaa8","executionInfo":{"status":"ok","timestamp":1584743930702,"user_tz":0,"elapsed":2119,"user":{"displayName":"David Massegur","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjPdhI-xRflKGWfi6g6h7PuXGRiA48J_SQUfTBPGw=s64","userId":"15590998365704503071"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["# In this exercise you will train a CNN on the FULL Cats-v-dogs dataset\n","# This will require you doing a lot of data preprocessing because\n","# the dataset isn't split into training and validation for you\n","# This code block has all the required inputs\n","import os\n","import zipfile\n","import random\n","%tensorflow_version 2.x\n","import tensorflow as tf\n","print(tf.__version__)\n","from tensorflow.keras.optimizers import RMSprop\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from shutil import copyfile"],"execution_count":0,"outputs":[{"output_type":"stream","text":["TensorFlow 2.x selected.\n","2.1.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"3sd9dQWa23aj","colab_type":"code","outputId":"87c5853a-ee79-4b36-a7ad-c26850ae0b62","executionInfo":{"status":"ok","timestamp":1584743981457,"user_tz":0,"elapsed":52858,"user":{"displayName":"David Massegur","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjPdhI-xRflKGWfi6g6h7PuXGRiA48J_SQUfTBPGw=s64","userId":"15590998365704503071"}},"colab":{"base_uri":"https://localhost:8080/","height":204}},"source":["# This code block downloads the full Cats-v-Dogs dataset and stores it as \n","# cats-and-dogs.zip. It then unzips it to /tmp\n","# which will create a tmp/PetImages directory containing subdirectories\n","# called 'Cat' and 'Dog' (that's how the original researchers structured it)\n","# If the URL doesn't work, \n","# .   visit https://www.microsoft.com/en-us/download/confirmation.aspx?id=54765\n","# And right click on the 'Download Manually' link to get a new URL\n","\n","!wget --no-check-certificate \\\n","    \"https://download.microsoft.com/download/3/E/1/3E1C3F21-ECDB-4869-8368-6DEBA77B919F/kagglecatsanddogs_3367a.zip\" \\\n","    -O \"/tmp/cats-and-dogs.zip\"\n","\n","local_zip = '/tmp/cats-and-dogs.zip'\n","zip_ref = zipfile.ZipFile(local_zip, 'r')\n","zip_ref.extractall('/tmp')\n","zip_ref.close()\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["--2020-03-20 22:38:51--  https://download.microsoft.com/download/3/E/1/3E1C3F21-ECDB-4869-8368-6DEBA77B919F/kagglecatsanddogs_3367a.zip\n","Resolving download.microsoft.com (download.microsoft.com)... 23.53.252.195, 2600:1406:3f:3a0::e59, 2600:1406:3f:384::e59\n","Connecting to download.microsoft.com (download.microsoft.com)|23.53.252.195|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 824894548 (787M) [application/octet-stream]\n","Saving to: ‘/tmp/cats-and-dogs.zip’\n","\n","/tmp/cats-and-dogs. 100%[===================>] 786.68M  18.9MB/s    in 41s     \n","\n","2020-03-20 22:39:33 (19.1 MB/s) - ‘/tmp/cats-and-dogs.zip’ saved [824894548/824894548]\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"gi3yD62a6X3S","colab_type":"code","outputId":"a667ee58-95b9-4324-9a27-acc6a304d6ed","executionInfo":{"status":"ok","timestamp":1584743981459,"user_tz":0,"elapsed":52846,"user":{"displayName":"David Massegur","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjPdhI-xRflKGWfi6g6h7PuXGRiA48J_SQUfTBPGw=s64","userId":"15590998365704503071"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["print(len(os.listdir('/tmp/PetImages/Cat/')))\n","print(len(os.listdir('/tmp/PetImages/Dog/')))\n","\n","# Expected Output:\n","# 12501\n","# 12501"],"execution_count":0,"outputs":[{"output_type":"stream","text":["12501\n","12501\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"F-QkLjxpmyK2","colab_type":"code","outputId":"a5d7462a-8959-4863-c51c-ba96ef08edd6","executionInfo":{"status":"ok","timestamp":1584743985579,"user_tz":0,"elapsed":56953,"user":{"displayName":"David Massegur","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjPdhI-xRflKGWfi6g6h7PuXGRiA48J_SQUfTBPGw=s64","userId":"15590998365704503071"}},"colab":{"base_uri":"https://localhost:8080/","height":187}},"source":["# Use os.mkdir to create your directories\n","# You will need a directory for cats-v-dogs, and subdirectories for training\n","# and testing. These in turn will need subdirectories for 'cats' and 'dogs'\n","try:\n","    #YOUR CODE GOES HERE\n","    print(os.getcwd())\n","    print( os.listdir('/content/') )\n","    os.chdir('/tmp/')  # to change directory\n","    print(os.getcwd())\n","    !ls\n","    os.chdir('/tmp/PetImages/')\n","    print(os.getcwd())\n","    !ls\n","    os.chdir('/tmp/')\n","    os.mkdir('cats-v-dogs')\n","    !ls\n","    os.chdir('/tmp/cats-v-dogs/')    \n","    # os.mkdir('training')    \n","    print(os.getcwd())    \n","    print( os.listdir(os.getcwd()) )    # !ls\n","\n","except OSError:\n","    print('error encountered trying to create directory.')\n","    pass\n","\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["/content\n","['.config', 'sample_data']\n","/tmp\n"," cats-and-dogs.zip  'MSR-LA - 3467.docx'   PetImages  'readme[1].txt'\n","/tmp/PetImages\n","Cat  Dog\n"," cats-and-dogs.zip  'MSR-LA - 3467.docx'  'readme[1].txt'\n"," cats-v-dogs\t     PetImages\n","/tmp/cats-v-dogs\n","[]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"l9IVDMD0cPRh","colab_type":"code","outputId":"f9701c9a-8655-48d7-e535-7ff8aaccfacc","executionInfo":{"status":"ok","timestamp":1584743985582,"user_tz":0,"elapsed":56942,"user":{"displayName":"David Massegur","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjPdhI-xRflKGWfi6g6h7PuXGRiA48J_SQUfTBPGw=s64","userId":"15590998365704503071"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["try:\n","    #YOUR CODE GOES HERE\n","    os.chdir('/tmp/cats-v-dogs/')    \n","    os.mkdir('training')    \n","    os.mkdir('testing')   \n","    print(os.getcwd())    \n","    print( os.listdir(os.getcwd()) )    # !ls\n","\n","except OSError:\n","    print('error encountered trying to create directory.')\n","    pass"],"execution_count":0,"outputs":[{"output_type":"stream","text":["/tmp/cats-v-dogs\n","['testing', 'training']\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"5BBfrPJGcevD","colab_type":"code","outputId":"65f786b9-dee5-4113-ff2d-6e67a24c8993","executionInfo":{"status":"ok","timestamp":1584743985584,"user_tz":0,"elapsed":56932,"user":{"displayName":"David Massegur","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjPdhI-xRflKGWfi6g6h7PuXGRiA48J_SQUfTBPGw=s64","userId":"15590998365704503071"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["try:\n","    #YOUR CODE GOES HERE\n","    os.chdir('/tmp/cats-v-dogs/training')    \n","    os.mkdir('cats')    \n","    os.mkdir('dogs')   \n","    print(os.getcwd())    \n","    print( os.listdir(os.getcwd()) )    # !ls\n","\n","except OSError:\n","    print('error encountered trying to create directory.')\n","    pass"],"execution_count":0,"outputs":[{"output_type":"stream","text":["/tmp/cats-v-dogs/training\n","['dogs', 'cats']\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"CmMfH1j6co2y","colab_type":"code","outputId":"77e2d873-527b-463d-cc81-38148b8bd8f5","executionInfo":{"status":"ok","timestamp":1584743985587,"user_tz":0,"elapsed":56922,"user":{"displayName":"David Massegur","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjPdhI-xRflKGWfi6g6h7PuXGRiA48J_SQUfTBPGw=s64","userId":"15590998365704503071"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["try:\n","    #YOUR CODE GOES HERE\n","    os.chdir('/tmp/cats-v-dogs/testing')    \n","    os.mkdir('cats')    \n","    os.mkdir('dogs')   \n","    print(os.getcwd())    \n","    print( os.listdir(os.getcwd()) )    # !ls\n","\n","except OSError:\n","    print('error encountered trying to create directory.')\n","    pass"],"execution_count":0,"outputs":[{"output_type":"stream","text":["/tmp/cats-v-dogs/testing\n","['dogs', 'cats']\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"zvSODo0f9LaU","colab_type":"code","outputId":"8ca11435-5ce7-471c-a51f-1bed86949438","executionInfo":{"status":"ok","timestamp":1584743989061,"user_tz":0,"elapsed":60384,"user":{"displayName":"David Massegur","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjPdhI-xRflKGWfi6g6h7PuXGRiA48J_SQUfTBPGw=s64","userId":"15590998365704503071"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["# Write a python function called split_data which takes\n","# a SOURCE directory containing the files\n","# a TRAINING directory that a portion of the files will be copied to\n","# a TESTING directory that a portion of the files will be copie to\n","# a SPLIT SIZE to determine the portion\n","# The files should also be randomized, so that the training set is a random\n","# X% of the files, and the test set is the remaining files\n","# So, for example, if SOURCE is PetImages/Cat, and SPLIT SIZE is .9\n","# Then 90% of the images in PetImages/Cat will be copied to the TRAINING dir\n","# and 10% of the images will be copied to the TESTING dir\n","# Also -- All images should be checked, and if they have a zero file length,\n","# they will not be copied over\n","#\n","# os.listdir(DIRECTORY) gives you a listing of the contents of that directory\n","# os.path.getsize(PATH) gives you the size of the file\n","# copyfile(source, destination) copies a file from source to destination\n","# random.sample(list, len(list)) shuffles a list\n","def split_data(SOURCE, TRAINING, TESTING, SPLIT_SIZE):\n","\n","  # YOUR CODE STARTS HERE\n","  source_img_names = os.listdir(SOURCE)  # this is a list containing all the image file names.\n","  source_img_names = random.sample(source_img_names, len(source_img_names))\n","  train_size = int(split_size * len(source_img_names))\n","  # test_size = len(source_img_names) - train_size\n","\n","  for i, name in enumerate(source_img_names):\n","\n","    source_file_path = os.path.join(SOURCE, name)\n","\n","    if os.path.getsize(source_file_path) > 0.0 :\n","\n","      if i<train_size:      \n","        target_file_path = os.path.join(TRAINING, name)\n","      else :\n","        target_file_path = os.path.join(TESTING, name)        \n","    \n","      copyfile(source_file_path, target_file_path)\n","\n","    else :\n","      print('%s has zero length: ignored' %source_file_path)\n","\n","  # YOUR CODE ENDS HERE\n","\n","\n","CAT_SOURCE_DIR = \"/tmp/PetImages/Cat/\"\n","TRAINING_CATS_DIR = \"/tmp/cats-v-dogs/training/cats/\"\n","TESTING_CATS_DIR = \"/tmp/cats-v-dogs/testing/cats/\"\n","DOG_SOURCE_DIR = \"/tmp/PetImages/Dog/\"\n","TRAINING_DOGS_DIR = \"/tmp/cats-v-dogs/training/dogs/\"\n","TESTING_DOGS_DIR = \"/tmp/cats-v-dogs/testing/dogs/\"\n","\n","split_size = .9\n","split_data(CAT_SOURCE_DIR, TRAINING_CATS_DIR, TESTING_CATS_DIR, split_size)\n","split_data(DOG_SOURCE_DIR, TRAINING_DOGS_DIR, TESTING_DOGS_DIR, split_size)\n","\n","# Expected output\n","# 666.jpg is zero length, so ignoring\n","# 11702.jpg is zero length, so ignoring\n","\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["/tmp/PetImages/Cat/666.jpg has zero length: ignored\n","/tmp/PetImages/Dog/11702.jpg has zero length: ignored\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"luthalB76ufC","colab_type":"code","outputId":"984a62da-9a84-4085-9f3f-6fbca2acacb1","executionInfo":{"status":"ok","timestamp":1584743989064,"user_tz":0,"elapsed":60375,"user":{"displayName":"David Massegur","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjPdhI-xRflKGWfi6g6h7PuXGRiA48J_SQUfTBPGw=s64","userId":"15590998365704503071"}},"colab":{"base_uri":"https://localhost:8080/","height":85}},"source":["# print(len(os.listdir('/tmp/cats-v-dogs/training/cats/')))\n","# print(len(os.listdir('/tmp/cats-v-dogs/training/dogs/')))\n","# print(len(os.listdir('/tmp/cats-v-dogs/testing/cats/')))\n","# print(len(os.listdir('/tmp/cats-v-dogs/testing/dogs/')))\n","\n","base_dir = '/tmp/cats-v-dogs/'\n","print(len(os.listdir(os.path.join(base_dir,'training','cats'))))\n","print(len(os.listdir(os.path.join(base_dir,'training','dogs'))))\n","print(len(os.listdir(os.path.join(base_dir,'testing','cats'))))\n","print(len(os.listdir(os.path.join(base_dir,'testing','dogs'))))\n","\n","# Expected output:\n","# 11250\n","# 11250\n","# 1250\n","# 1250"],"execution_count":0,"outputs":[{"output_type":"stream","text":["11249\n","11249\n","1251\n","1251\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"-BQrav4anTmj","colab_type":"code","outputId":"84ec9f2f-b14a-45aa-83ea-456145b8b21d","executionInfo":{"status":"ok","timestamp":1584744002256,"user_tz":0,"elapsed":73554,"user":{"displayName":"David Massegur","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjPdhI-xRflKGWfi6g6h7PuXGRiA48J_SQUfTBPGw=s64","userId":"15590998365704503071"}},"colab":{"base_uri":"https://localhost:8080/","height":527}},"source":["img_size = 150\n","\n","# DEFINE A KERAS MODEL TO CLASSIFY CATS V DOGS\n","# USE AT LEAST 3 CONVOLUTION LAYERS\n","model = tf.keras.models.Sequential([\n","  # YOUR CODE HERE\n","  tf.keras.layers.Conv2D(16, (3, 3), activation='relu', input_shape=(img_size, img_size, 3)),\n","  tf.keras.layers.MaxPool2D(2, 2),\n","  tf.keras.layers.Conv2D(32, (3, 3), activation='relu'),\n","  tf.keras.layers.MaxPool2D(2, 2),\n","  tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n","  tf.keras.layers.MaxPool2D(2, 2),\n","  tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n","  # tf.keras.layers.MaxPool2D(2, 2),\n","  tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n","  # tf.keras.layers.MaxPool2D(2, 2),\n","  tf.keras.layers.Flatten(),\n","  tf.keras.layers.Dense(1024, activation='relu'),\n","  # tf.keras.layers.Dropout(0.5),\n","  tf.keras.layers.Dense(1, activation='sigmoid'),\n","])\n","\n","model.summary()\n","\n","\n","from tensorflow.keras.optimizers import RMSprop\n","\n","model.compile(optimizer=RMSprop(lr=0.001), loss='binary_crossentropy', metrics=['accuracy'])"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Model: \"sequential\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","conv2d (Conv2D)              (None, 148, 148, 16)      448       \n","_________________________________________________________________\n","max_pooling2d (MaxPooling2D) (None, 74, 74, 16)        0         \n","_________________________________________________________________\n","conv2d_1 (Conv2D)            (None, 72, 72, 32)        4640      \n","_________________________________________________________________\n","max_pooling2d_1 (MaxPooling2 (None, 36, 36, 32)        0         \n","_________________________________________________________________\n","conv2d_2 (Conv2D)            (None, 34, 34, 64)        18496     \n","_________________________________________________________________\n","max_pooling2d_2 (MaxPooling2 (None, 17, 17, 64)        0         \n","_________________________________________________________________\n","conv2d_3 (Conv2D)            (None, 15, 15, 64)        36928     \n","_________________________________________________________________\n","conv2d_4 (Conv2D)            (None, 13, 13, 64)        36928     \n","_________________________________________________________________\n","flatten (Flatten)            (None, 10816)             0         \n","_________________________________________________________________\n","dense (Dense)                (None, 1024)              11076608  \n","_________________________________________________________________\n","dense_1 (Dense)              (None, 1)                 1025      \n","=================================================================\n","Total params: 11,175,073\n","Trainable params: 11,175,073\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"mlNjoJ5D61N6","colab_type":"code","outputId":"1d11f8f4-e4d0-4366-8b2a-8e5c700ddf1e","executionInfo":{"status":"ok","timestamp":1584744002554,"user_tz":0,"elapsed":73840,"user":{"displayName":"David Massegur","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjPdhI-xRflKGWfi6g6h7PuXGRiA48J_SQUfTBPGw=s64","userId":"15590998365704503071"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["TRAINING_DIR = os.path.join(base_dir,'training')  #YOUR CODE HERE\n","train_datagen = ImageDataGenerator(\n","     #YOUR CODE HERE\n","     rescale=1/255,\n","     rotation_range=40,\n","     width_shift_range=0.2,\n","     height_shift_range=0.2,\n","     shear_range=0.2,\n","     zoom_range=0.2,\n","     horizontal_flip=True,\n","     fill_mode='nearest'\n",") \n","train_generator = train_datagen.flow_from_directory(\n","    #YOUR CODE HERE\n","    TRAINING_DIR,\n","    target_size=(img_size, img_size),\n","    batch_size = 128,\n","    class_mode='binary' \n",")  \n","\n","VALIDATION_DIR = os.path.join(base_dir,'testing')  #YOUR CODE HERE\n","validation_datagen = ImageDataGenerator(rescale=1/255)  \n","    #YOUR CODE HERE\n","#     rescale=1/255,\n","#     rotation_range=40,\n","#     width_shift_range=0.2,\n","#     height_shift_range=0.2,\n","#     shear_range=0.2,\n","#     zoom_range=0.2,\n","#     horizontal_flip=True,\n","#     fill_mode='nearest'\n","# )\n","validation_generator = validation_datagen.flow_from_directory(\n","    #YOUR CODE HERE\n","    VALIDATION_DIR,\n","    target_size=(img_size, img_size),\n","    batch_size=32,\n","    class_mode='binary'\n",")\n","\n","\n","# Expected Output:\n","# Found 22498 images belonging to 2 classes.\n","# Found 2500 images belonging to 2 classes."],"execution_count":0,"outputs":[{"output_type":"stream","text":["Found 22496 images belonging to 2 classes.\n","Found 2502 images belonging to 2 classes.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"KyS4n53w7DxC","colab_type":"code","outputId":"d6bc11e9-f379-4a0c-bb5f-66324d515e3f","executionInfo":{"status":"error","timestamp":1584666005801,"user_tz":0,"elapsed":13717750,"user":{"displayName":"David Massegur","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjPdhI-xRflKGWfi6g6h7PuXGRiA48J_SQUfTBPGw=s64","userId":"15590998365704503071"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["# Callback to stop the training:\n","class myCallback(tf.keras.callbacks.Callback):\n","  def on_epoch_end(self, epoch, logs={}):\n","    target=0.999\n","    if (logs['accuracy']>target):\n","      print('Reached %0.1f%% training accuracty. Training converged!' %(target*100))\n","      self.model.stop_training=True\n","\n","callback = myCallback()\n","\n","\n","history = model.fit_generator(train_generator,\n","                              steps_per_epoch = train_generator.n//train_generator.batch_size,\n","                              epochs=50,\n","                              validation_data=validation_generator,\n","                              validation_steps = validation_generator.n//validation_generator.batch_size,\n","                              verbose=1)\n","\n","# The expectation here is that the model will train, and that accuracy will be > 95% on both training and validation\n","# i.e. acc:A1 and val_acc:A2 will be visible, and both A1 and A2 will be > .9"],"execution_count":0,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From <ipython-input-12-a9521ebb1660>:16: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use Model.fit, which supports generators.\n","WARNING:tensorflow:sample_weight modes were coerced from\n","  ...\n","    to  \n","  ['...']\n","WARNING:tensorflow:sample_weight modes were coerced from\n","  ...\n","    to  \n","  ['...']\n","Train for 175 steps, validate for 78 steps\n","Epoch 1/50\n"," 58/175 [========>.....................] - ETA: 1:53 - loss: 0.8357 - accuracy: 0.5203"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/PIL/TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 32 bytes but only got 0. Skipping tag 270\n","  \" Skipping tag %s\" % (size, len(data), tag)\n","/usr/local/lib/python3.6/dist-packages/PIL/TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 5 bytes but only got 0. Skipping tag 271\n","  \" Skipping tag %s\" % (size, len(data), tag)\n","/usr/local/lib/python3.6/dist-packages/PIL/TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 8 bytes but only got 0. Skipping tag 272\n","  \" Skipping tag %s\" % (size, len(data), tag)\n","/usr/local/lib/python3.6/dist-packages/PIL/TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 8 bytes but only got 0. Skipping tag 282\n","  \" Skipping tag %s\" % (size, len(data), tag)\n","/usr/local/lib/python3.6/dist-packages/PIL/TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 8 bytes but only got 0. Skipping tag 283\n","  \" Skipping tag %s\" % (size, len(data), tag)\n","/usr/local/lib/python3.6/dist-packages/PIL/TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 20 bytes but only got 0. Skipping tag 306\n","  \" Skipping tag %s\" % (size, len(data), tag)\n","/usr/local/lib/python3.6/dist-packages/PIL/TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 48 bytes but only got 0. Skipping tag 532\n","  \" Skipping tag %s\" % (size, len(data), tag)\n","/usr/local/lib/python3.6/dist-packages/PIL/TiffImagePlugin.py:788: UserWarning: Corrupt EXIF data.  Expecting to read 2 bytes but only got 0. \n","  warnings.warn(str(msg))\n"],"name":"stderr"},{"output_type":"stream","text":["175/175 [==============================] - 168s 957ms/step - loss: 0.7396 - accuracy: 0.5376 - val_loss: 0.6814 - val_accuracy: 0.5264\n","Epoch 2/50\n","175/175 [==============================] - 162s 924ms/step - loss: 0.6705 - accuracy: 0.5902 - val_loss: 0.6806 - val_accuracy: 0.6374\n","Epoch 3/50\n","175/175 [==============================] - 160s 912ms/step - loss: 0.6329 - accuracy: 0.6507 - val_loss: 0.5818 - val_accuracy: 0.6971\n","Epoch 4/50\n","175/175 [==============================] - 163s 933ms/step - loss: 0.6018 - accuracy: 0.6782 - val_loss: 0.5181 - val_accuracy: 0.7416\n","Epoch 5/50\n","175/175 [==============================] - 162s 928ms/step - loss: 0.5787 - accuracy: 0.6959 - val_loss: 0.4821 - val_accuracy: 0.7712\n","Epoch 6/50\n","175/175 [==============================] - 160s 913ms/step - loss: 0.5567 - accuracy: 0.7147 - val_loss: 0.7979 - val_accuracy: 0.5609\n","Epoch 7/50\n","175/175 [==============================] - 159s 908ms/step - loss: 0.5365 - accuracy: 0.7340 - val_loss: 0.4410 - val_accuracy: 0.7917\n","Epoch 8/50\n","175/175 [==============================] - 158s 903ms/step - loss: 0.5144 - accuracy: 0.7469 - val_loss: 0.4309 - val_accuracy: 0.8005\n","Epoch 9/50\n","175/175 [==============================] - 159s 908ms/step - loss: 0.4969 - accuracy: 0.7593 - val_loss: 0.5667 - val_accuracy: 0.6783\n","Epoch 10/50\n","175/175 [==============================] - 159s 908ms/step - loss: 0.4720 - accuracy: 0.7728 - val_loss: 0.3886 - val_accuracy: 0.8233\n","Epoch 11/50\n","175/175 [==============================] - 158s 906ms/step - loss: 0.4588 - accuracy: 0.7841 - val_loss: 0.3957 - val_accuracy: 0.8209\n","Epoch 12/50\n","175/175 [==============================] - 158s 905ms/step - loss: 0.4381 - accuracy: 0.7916 - val_loss: 0.3459 - val_accuracy: 0.8498\n","Epoch 13/50\n","175/175 [==============================] - 158s 904ms/step - loss: 0.4287 - accuracy: 0.8018 - val_loss: 0.4374 - val_accuracy: 0.8073\n","Epoch 14/50\n","175/175 [==============================] - 158s 902ms/step - loss: 0.4081 - accuracy: 0.8127 - val_loss: 0.3257 - val_accuracy: 0.8674\n","Epoch 15/50\n","175/175 [==============================] - 159s 910ms/step - loss: 0.3987 - accuracy: 0.8173 - val_loss: 0.3346 - val_accuracy: 0.8594\n","Epoch 16/50\n","175/175 [==============================] - 159s 908ms/step - loss: 0.3810 - accuracy: 0.8276 - val_loss: 0.3056 - val_accuracy: 0.8722\n","Epoch 17/50\n","175/175 [==============================] - 158s 905ms/step - loss: 0.3695 - accuracy: 0.8355 - val_loss: 0.3656 - val_accuracy: 0.8369\n","Epoch 18/50\n","175/175 [==============================] - 159s 908ms/step - loss: 0.3549 - accuracy: 0.8401 - val_loss: 0.2600 - val_accuracy: 0.8966\n","Epoch 19/50\n","175/175 [==============================] - 158s 901ms/step - loss: 0.3447 - accuracy: 0.8467 - val_loss: 0.2536 - val_accuracy: 0.9006\n","Epoch 20/50\n","175/175 [==============================] - 158s 903ms/step - loss: 0.3296 - accuracy: 0.8539 - val_loss: 0.2588 - val_accuracy: 0.8962\n","Epoch 21/50\n","175/175 [==============================] - 158s 902ms/step - loss: 0.3199 - accuracy: 0.8605 - val_loss: 0.3104 - val_accuracy: 0.8722\n","Epoch 22/50\n","175/175 [==============================] - 159s 909ms/step - loss: 0.3131 - accuracy: 0.8637 - val_loss: 0.2245 - val_accuracy: 0.9127\n","Epoch 23/50\n","175/175 [==============================] - 157s 897ms/step - loss: 0.3070 - accuracy: 0.8674 - val_loss: 0.2321 - val_accuracy: 0.9067\n","Epoch 24/50\n","175/175 [==============================] - 157s 897ms/step - loss: 0.2948 - accuracy: 0.8726 - val_loss: 0.6630 - val_accuracy: 0.7800\n","Epoch 25/50\n","175/175 [==============================] - 158s 904ms/step - loss: 0.2893 - accuracy: 0.8750 - val_loss: 0.2841 - val_accuracy: 0.8810\n","Epoch 26/50\n","146/175 [========================>.....] - ETA: 24s - loss: 0.2837 - accuracy: 0.8755"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"MWZrJN4-65RC","colab_type":"code","colab":{}},"source":["# PLOT LOSS AND ACCURACY\n","%matplotlib inline\n","\n","import matplotlib.image  as mpimg\n","import matplotlib.pyplot as plt\n","\n","#-----------------------------------------------------------\n","# Retrieve a list of list results on training and test data\n","# sets for each training epoch\n","#-----------------------------------------------------------\n","acc=history.history['accuracy']\n","val_acc=history.history['val_accuracy']\n","loss=history.history['loss']\n","val_loss=history.history['val_loss']\n","\n","epochs=range(len(acc)) # Get number of epochs\n","\n","#------------------------------------------------\n","# Plot training and validation accuracy per epoch\n","#------------------------------------------------\n","plt.plot(epochs, acc, 'r', \"Training Accuracy\")\n","plt.plot(epochs, val_acc, 'b', \"Validation Accuracy\")\n","plt.title('Training and validation accuracy')\n","plt.legend()\n","\n","plt.figure()\n","\n","#------------------------------------------------\n","# Plot training and validation loss per epoch\n","#------------------------------------------------\n","plt.plot(epochs, loss, 'r', \"Training Loss\")\n","plt.plot(epochs, val_loss, 'b', \"Validation Loss\")\n","plt.legend()\n","plt.title('Training and validation loss')\n","\n","# Desired output. Charts with training and validation metrics. No crash :)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"LqL6FYUrtXpf","colab_type":"code","colab":{}},"source":["# Here's a codeblock just for fun. You should be able to upload an image here \n","# and have it classified without crashing\n","\n","import numpy as np\n","from google.colab import files\n","from keras.preprocessing import image\n","\n","\n","os.chdir('/content/')\n","print(os.getcwd())\n","print(os.listdir())\n","\n","uploaded = files.upload()\n","\n","for fn in uploaded.keys():\n"," \n","  # predicting images\n","  path = '/content/' + fn\n","  img = image.load_img(path, target_size=(img_size, img_size))\n","  x = image.img_to_array(img)\n","  x = np.expand_dims(x, axis=0)\n","\n","  images = np.vstack([x])\n","  classes = model.predict(images, batch_size=10)\n","  print(classes[0])\n","  if classes[0]>0.5:\n","    print(fn + \" is a dog\")\n","  else:\n","    print(fn + \" is a cat\")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"cYJKsJYsxfoE","colab_type":"code","colab":{}},"source":["# Clean-up:\n","import os, signal\n","\n","os.kill( os.getpid(), signal.SIGKILL )"],"execution_count":0,"outputs":[]}]}